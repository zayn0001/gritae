{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStore(id='vs_0yhzHPvJzcQT66OJ23HtNfRp', created_at=1717766228, file_counts=FileCounts(cancelled=0, completed=0, failed=0, in_progress=0, total=0), last_active_at=1717766228, metadata={}, name='GRITAE2', object='vector_store', status='completed', usage_bytes=0, expires_after=None, expires_at=None)\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "vector_store = client.beta.vector_stores.create(\n",
    "  name=\"GRITAE2\"\n",
    ")\n",
    "print(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[VectorStoreFile](data=[VectorStoreFile(id='file-MUUy46T4HmjR1ylBCit5vpF5', created_at=1717765253, last_error=None, object='vector_store.file', status='completed', usage_bytes=653708, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-MyyxS1VHkBQPQuJ6THPYH94S', created_at=1717765252, last_error=None, object='vector_store.file', status='completed', usage_bytes=720855, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-DBWXLsIg8aNax7I7e8sfsq4l', created_at=1717765251, last_error=None, object='vector_store.file', status='completed', usage_bytes=692515, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-2aXiNodOOINi9D0f5TCgPEHw', created_at=1717765251, last_error=None, object='vector_store.file', status='completed', usage_bytes=653941, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-CwVkSX9hlB1BxxyesoUbkg9U', created_at=1717765250, last_error=None, object='vector_store.file', status='completed', usage_bytes=711640, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-UMW3YLtChT4zvqivnjwzTO6D', created_at=1717765249, last_error=None, object='vector_store.file', status='completed', usage_bytes=726462, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-Xs3FJ6raKSQ7LSezxWSq2sDp', created_at=1717765248, last_error=None, object='vector_store.file', status='completed', usage_bytes=681938, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-NDYEdT0ZRRYOxdNpR5GPKws7', created_at=1717765247, last_error=None, object='vector_store.file', status='completed', usage_bytes=662617, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-VR8jCgSHFWmY63JSn2n7oWkT', created_at=1717765246, last_error=None, object='vector_store.file', status='completed', usage_bytes=721496, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-Mekxe2zazNQplX4csKSHZljt', created_at=1717765245, last_error=None, object='vector_store.file', status='completed', usage_bytes=715872, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-NCOWOKjEDqbF10EUuJb4q32B', created_at=1717765244, last_error=None, object='vector_store.file', status='completed', usage_bytes=674354, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-vT6vYy49aVk8TBhGU3WNy28p', created_at=1717765244, last_error=None, object='vector_store.file', status='completed', usage_bytes=726387, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-5b3ajpvdP0cjVOMxk3rRpfeh', created_at=1717765243, last_error=None, object='vector_store.file', status='completed', usage_bytes=742453, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-GvJLfj5drq1YhbU69Nedk1E0', created_at=1717765242, last_error=None, object='vector_store.file', status='completed', usage_bytes=664153, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-rtnL23xzzQdx9AdErnTPiT84', created_at=1717765242, last_error=None, object='vector_store.file', status='completed', usage_bytes=668556, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-V093G0WEVVGhAe9KCpGJFgbE', created_at=1717765240, last_error=None, object='vector_store.file', status='completed', usage_bytes=692026, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-2Z5jpTepGefpsifvCLTlsk3w', created_at=1717765240, last_error=None, object='vector_store.file', status='completed', usage_bytes=678351, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-22opSkPj2Zegq4NgTEVod7hm', created_at=1717765238, last_error=None, object='vector_store.file', status='completed', usage_bytes=726102, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-U7apK85tNFI6JCcUDvKVc81Z', created_at=1717765238, last_error=None, object='vector_store.file', status='completed', usage_bytes=719200, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-vE54vNiuNV4dk34Reb8uvvHm', created_at=1717765237, last_error=None, object='vector_store.file', status='completed', usage_bytes=720296, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}})], object='list', first_id='file-MUUy46T4HmjR1ylBCit5vpF5', last_id='file-vE54vNiuNV4dk34Reb8uvvHm', has_more=True)\n"
     ]
    }
   ],
   "source": [
    "vector_store_files = client.beta.vector_stores.files.list(\n",
    "  vector_store_id=\"vs_VwMZZPLE2n0cmHr0oqSgFzGL\"\n",
    ")\n",
    "print(vector_store_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(vector_store_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_O2HWobGq5XTAMxMJCt0bMiMT', created_at=1717830712, description=None, instructions='You have been given HTML documents of case studies of projects done for different companies in the past. You will be provided the about page of a website of a company that deals in a specific field of IT servicing. You are to provide the name of the company that corresponds to the most similar case study, and also 3 reasons why that case study is worth going through by the prospect that is, how it could be beneficial for them. in json format only. Example output: {\"url\":\"www.ABC.com\", \"points\":[\"We have helped ABC do X more efficiently which also could benefit you as you deal in similar fields\", \"We incorporated X into the ABC ecosystem... \", \" We helped ABC do this better, you could use it too.....\"]}', metadata={}, model='gpt-4o', name='GRITAE', object='assistant', tools=[FileSearchTool(type='file_search')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=['vs_VwMZZPLE2n0cmHr0oqSgFzGL'])), top_p=1.0)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions=\"You have been given HTML documents of case studies of projects done for different companies in the past.\"\n",
    "    \" You will be provided the about page of a website of a company that deals in a specific field of IT servicing.\"\n",
    "    \" You are to provide the name of the company that corresponds to the most similar case study, \"\n",
    "    \"and also 3 reasons why that case study is worth going through by the prospect that is, how it could be beneficial for them.\"\n",
    "    \" in json format only. \" \n",
    "    \"Example output: {\\\"url\\\":\\\"www.ABC.com\\\", \\\"points\\\":[\\\"We have helped ABC do X more efficiently which also could benefit you as you deal in similar fields\\\", \\\"We incorporated X into the ABC ecosystem... \\\", \\\" We helped ABC do this better, you could use it too.....\\\"]}\",\n",
    "    name=\"GRITAE\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    "    model=\"gpt-4o\", \n",
    "    tool_resources={\n",
    "    \"file_search\": {\n",
    "      \"vector_store_ids\": [\"vs_VwMZZPLE2n0cmHr0oqSgFzGL\"]\n",
    "    },\n",
    "    }\n",
    ")\n",
    "print(my_assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_EdCxX673x1nFzLPZhlD3yUZW', created_at=1717768602, description=None, instructions='', metadata={}, model='gpt-4o', name='GRITAE2', object='assistant', tools=[], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions=\"\",\n",
    "    name=\"GRITAE2\",\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "print(my_assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=\"asst_EdCxX673x1nFzLPZhlD3yUZW\",\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=\"You will be given a list of endpoints of a particular website. You are to provide back the website link that is most likely to be the about page of the website. Return nothing but the link. The list is as follows: \"+str()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def extract_json_substring(text):\n",
    "    # Define the regex pattern to match content between ```json and ```, excluding the markers\n",
    "    pattern = r'```json\\s*(.*?)\\s*```'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        # Extract and return the substring\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        # Return None if no match is found\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions=\"You have been given HTML documents of case studies of projects done for different companies in the past.\"\n",
    "    \" You will be provided the about page of a website of a company that deals in a specific field of IT servicing.\"\n",
    "    \" You are to provide the name of the company that corresponds to the most similar case study, \"\n",
    "    \"and also 3 reasons why that case study is worth going through by the prospect that is, how it could be beneficial for them.\"\n",
    "    \" in json format only. \" \n",
    "    \"Example output: {\\\"url\\\":\\\"www.ABC.com\\\", \\\"points\\\":[\\\"We have helped ABC do X more efficiently which also could benefit you as you deal in similar fields\\\", \\\"We incorporated X into the ABC ecosystem... \\\", \\\" We helped ABC do this better, you could use it too.....\\\"]}\",\n",
    "    name=\"GRITAE\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    "    model=\"gpt-4o\", \n",
    "    tool_resources={\n",
    "    \"file_search\": {\n",
    "      \"vector_store_ids\": [\"vs_VwMZZPLE2n0cmHr0oqSgFzGL\"]\n",
    "    },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = \"Loops is a company that develops an email platform designed for early-stage B2B SaaS companies, helping them manage email campaigns, automated onboarding, retention, and reengagement emails for their customers. Backed by Y Combinator, the company is focused on rapidly building new features and prides itself on consistently delivering quality work despite being a small team.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI()\n",
    "thread = client.beta.threads.create()\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=my_assistant.id,\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=\"You have been given HTML documents of case studies for companies done for different companies in the past.\"\n",
    "    \"I will provide the summary of a company. Find the most similar case study that fits the needs of this company and provide 3 reasons why the case study is worth looking into.\"\n",
    "    \"Provide in json format only and nothing extra.\" \n",
    "    \"Example output: {\\\"case_study\\\":\\\"Fundrise\\\", \\\"case_study_link\\\":\\\"https://www.intercom.com/customers/fundrise\\\", \\\"company_link\\\":\\\"https://fundrise.com/\\\"  \\\"reasons\\\":[\\\"We have helped ABC do X more efficiently which also could benefit you because...\\\", \\\"We incorporated X into the ABC ecosystem... \\\", \\\" We helped ABC do this better, you could use it too.....\\\"]}\"\n",
    "    \"The summary of the company is as follows: \" + summary\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'case_study': 'WebinarGeek', 'case_study_link': 'https://www.intercom.com/customers/webinargeek', 'company_link': 'https://www.webinargeek.com/', 'reasons': [\"WebinarGeek started as an early-stage company and used Intercom's Early Stage Program to transform their customer communications, which aligns with your current stage and need for a robust yet scalable solution.\", \"They saw a significant 35% increase in trial-to-paid conversion rates by using personalized and targeted email campaigns via Intercom's Series feature. This could be particularly valuable for Loops' focus on automated onboarding and engagement.\", 'The consolidation of their tech stack was crucial for WebinarGeek, enabling them to manage support, sales, and marketing seamlessly. This would benefit Loops by integrating various functions within a single platform.']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "if run.status == \"completed\":\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        text = messages.data[0].content[0].text.value\n",
    "        text = extract_json_substring(text)\n",
    "        text = re.sub(r'【.*?】', '', text)\n",
    "        text = text.replace(\"```json\", \"\").replace(\"```\",\"\")\n",
    "        text = json.loads(text)\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company. Engineering. as well as great founders from companies like. Terms of Service. That’s it! Have a great day 👋. our open roles. Send your first email. Send transactional email. We're the small but mighty team behind Loops.. Log in. company, backed by. View all. Lattice. and more.. We’re building an email platform for early-stage B2B SaaS companies.. Dan Rowden. Chris. Kyle Suss. Chris Frantz. Adam Kaczmarek. © 2024 Astrodon Inc.. We've been lucky to stand on the shoulders of giants. We're a. Product. Focus. Public Wiki. Hey there!. Codecademy. Framer. Changelog. Dropbox. by the way, one of the two founders of Loops. We’re a small team but we try to put out great work consistently. If you'd like to join us on our mission, check out. Resources. ,. Credits. Build a waitlist. I’m. Bounce Doctor. Pricing. Privacy. We take care of sending email campaigns for your product updates as well as automated onboarding, retention, and reengagement emails. We've got even more planned so stay tuned by joining the waitlist at the bottom of this page.. Our company is 2 years old and we're rapidly building our initial set of features.. .. Guides. Phil Brockman. Careers. Start. Email Examples. Glossary. Customers. Start here. Updates. Founder. The email platform for SaaS. Docs. Loops - About Us. About Us. Sam Wan. Craft. Y Combinator\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to fetch HTML content from a URL and extract text with line breaks\n",
    "def extract_text_with_line_breaks_from_url(url):\n",
    "    # Fetch the HTML content from the URL\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "    html_content = response.text\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Extract text with proper line breaks\n",
    "    text_with_line_breaks = '. '.join(list(set(soup.stripped_strings)))\n",
    "    \n",
    "\n",
    "    return text_with_line_breaks\n",
    "\n",
    "# URL of the web page\n",
    "url = 'https://www.loops.so/about'\n",
    "\n",
    "# Get the text from the URL\n",
    "text = extract_text_with_line_breaks_from_url(url)\n",
    "\n",
    "# Print the extracted text\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved https://www.loops.so/about to /tmp/tmp8bjiifv_.html\n",
      "/tmp/tmp8bjiifv_.html\n",
      "The company specializes in providing risk management solutions and services, which include risk assessment, mitigation strategies, and implementation support to help clients manage and minimize potential risks in their operations .\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def save_html_to_tempfile(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.html', mode='w', encoding='utf-8')\n",
    "        temp_file.write(response.text)\n",
    "        temp_file.close()\n",
    "        print(f'Successfully saved {url} to {temp_file.name}')\n",
    "        return temp_file.name\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f'Failed to retrieve {url}: {e}')\n",
    "        return None\n",
    "\n",
    "url = \"https://www.loops.so/about\"\n",
    "temp_file_path = save_html_to_tempfile(url)\n",
    "print(temp_file_path)\n",
    "vector_store = client.beta.vector_stores.create(\n",
    "  name=\"testing\"\n",
    ")\n",
    "cli =  client.files.create(file=open(temp_file_path, \"rb\"),purpose=\"assistants\")\n",
    "vector_store_file = client.beta.vector_stores.files.create(\n",
    "        vector_store_id=vector_store.id,\n",
    "        file_id=cli.id\n",
    "        )\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a company summarizer. you have access to the about page of the website of the company\",\n",
    "    name=\"testing\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")\n",
    "thread = client.beta.threads.create()\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=my_assistant.id,\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=\"Provide a brief single paragraph summary on what the company does\"\n",
    "    )\n",
    "if run.status == \"completed\":\n",
    "    messages = client.beta.threads.messages.list(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    text = messages.data[0].content[0].text.value\n",
    "    #text = extract_json_substring(text)\n",
    "    text = re.sub(r'【.*?】', '', text)\n",
    "    #text = text.replace(\"```json\", \"\").replace(\"```\",\"\")\n",
    "    #text = json.loads(text)\n",
    "    client.beta.vector_stores.delete(\n",
    "        vector_store_id=vector_store.id\n",
    "    )\n",
    "    client.beta.assistants.delete(assistant_id=my_assistant.id)\n",
    "    client.files.delete(file_id=cli.id)\n",
    "    client.beta.threads.delete(thread_id=thread.id)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loops is an email platform designed specifically for early-stage B2B SaaS companies, helping them manage product update campaigns and automate emails aimed at onboarding, retaining, and reengaging customers. Supported by notable investors like Lattice and Y Combinator, Loops enhances customer communication strategies for SaaS businesses.\n"
     ]
    }
   ],
   "source": [
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a company goals summarizer\",\n",
    "    name=\"testing\",\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "thread = client.beta.threads.create()\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=my_assistant.id,\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=\"Provide a brief single paragraph summary on what the following company does given the following sentences in their 'about' page: \"+ text\n",
    "    )\n",
    "if run.status == \"completed\":\n",
    "    messages = client.beta.threads.messages.list(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    text = messages.data[0].content[0].text.value\n",
    "    #text = extract_json_substring(text)\n",
    "    text = re.sub(r'【.*?】', '', text)\n",
    "    #text = text.replace(\"```json\", \"\").replace(\"```\",\"\")\n",
    "    #text = json.loads(text)\n",
    "    client.beta.assistants.delete(assistant_id=my_assistant.id)\n",
    "    client.beta.threads.delete(thread_id=thread.id)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "def get_single_nested_links(sitemap_url):\n",
    "    \"\"\"\n",
    "    Retrieve links from a sitemap.xml with a maximum of single nesting.\n",
    "    \n",
    "    :param sitemap_url: URL of the sitemap.xml\n",
    "    :return: List of filtered URLs\n",
    "    \"\"\"\n",
    "    \n",
    "    if sitemap_url[-1]!=\"/\":\n",
    "        sitemap_url += \"/\"\n",
    "    if not sitemap_url.startswith(\"https://\"):\n",
    "        sitemap_url = \"https://\" + sitemap_url\n",
    "        \n",
    "    sitemap_url += \"sitemap.xml\"\n",
    "\n",
    "    response = requests.get(sitemap_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to retrieve sitemap: {response.status_code}\")\n",
    "\n",
    "    sitemap_content = response.content\n",
    "    root = ET.fromstring(sitemap_content)\n",
    "    namespace = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "\n",
    "    single_nested_links = []\n",
    "    \n",
    "    for url in root.findall('ns:url', namespaces=namespace):\n",
    "        loc = url.find('ns:loc', namespaces=namespace).text\n",
    "        count = loc.count(\"/\")\n",
    "        if count<7:\n",
    "            single_nested_links.append(loc)\n",
    "\n",
    "    return single_nested_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_action\n",
      "Tool outputs submitted successfully.\n",
      "The about page for the given set of endpoints is [https://loops.so/about](https://loops.so/about).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ThreadDeleted(id='thread_JZ1LxMNWrj01irhDGImlFf1N', deleted=True, object='thread.deleted')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = get_single_nested_links(\"https://www.loops.so/\")\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are a website analyzer. You will provide the about page endpoint from a list of endpoints. Do not return anything but the endpoint and do not return it as a link\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_about_page\",\n",
    "        \"description\": \"Get the link that is most likely to be the about page of the website\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"links\": {\n",
    "              \"type\": \"array\",\n",
    "              \"description\": \"The list of endpoints of a website\",\n",
    "              \"items\":{\n",
    "                \"type\":\"string\"\n",
    "              }\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\"links\"]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "thread = client.beta.threads.create()\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Which one is the about page for the following set of endpoints: \"+str(links)\n",
    ")\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages)\n",
    "else:\n",
    "  print(run.status)\n",
    "tool_outputs = []\n",
    " \n",
    "# Loop through each tool in the required action section\n",
    "for tool in run.required_action.submit_tool_outputs.tool_calls:\n",
    "  if tool.function.name == \"get_about_page\":\n",
    "    tool_outputs.append({\n",
    "      \"tool_call_id\": tool.id,\n",
    "      \"output\": \"https://www.cognizant.com/us/en/about-cognizant\"\n",
    "    })\n",
    "\n",
    "if tool_outputs:\n",
    "  try:\n",
    "    run = client.beta.threads.runs.submit_tool_outputs_and_poll(\n",
    "      thread_id=thread.id,\n",
    "      run_id=run.id,\n",
    "      tool_outputs=tool_outputs\n",
    "    )\n",
    "    print(\"Tool outputs submitted successfully.\")\n",
    "  except Exception as e:\n",
    "    print(\"Failed to submit tool outputs:\", e)\n",
    "else:\n",
    "  print(\"No tool outputs to submit.\")\n",
    "\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages.data[0].content[0].text.value)\n",
    "else:\n",
    "  print(run.status)\n",
    "\n",
    "client.beta.assistants.delete(assistant_id=assistant.id)\n",
    "client.beta.threads.delete(thread_id=thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'de']\n",
      "['abcd', 'de']\n",
      "['abc', 'defg']\n",
      "['abc', 'def']\n",
      "['abc']\n",
      "['abc', 'def', 'ghi']\n",
      "['ab', 'cd', 'ef']\n",
      "['us', 'en', 'about-us']\n",
      "['us', 'en', 'xyz']\n",
      "['http://example.com/abc/def/ghi', 'http://example.com/ab/cd/ef', 'http://example.com/us/en/xyz']\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "def filter_endpoints(urls):\n",
    "    def is_singly_nested(path):\n",
    "        parts = path.strip('/').split('/')\n",
    "        print(parts)\n",
    "        return len(parts) < 2 and all(len(part) < 4 for part in parts)\n",
    "\n",
    "    result = []\n",
    "    for url in urls:\n",
    "        parsed_url = urlparse(url)\n",
    "        path = parsed_url.path\n",
    "        if is_singly_nested(path):\n",
    "            result.append(url)\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "urls = [\n",
    "    \"http://example.com/abc/de\",\n",
    "    \"http://example.com/abcd/de\",\n",
    "    \"http://example.com/abc/defg\",\n",
    "    \"http://example.com/abc/def\",\n",
    "    \"http://example.com/abc\",\n",
    "    \"http://example.com/abc/def/ghi\",\n",
    "    \"http://example.com/ab/cd/ef\",\n",
    "    \"http://example.com/us/en/about-us\",\n",
    "    \"http://example.com/us/en/xyz\"\n",
    "]\n",
    "\n",
    "filtered_urls = filter_endpoints(urls)\n",
    "print(filtered_urls)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
